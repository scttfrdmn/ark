# Ark: AWS Research Kit for UCLA
### Integrated Cloud Security Training & Tooling for Academic Research

**âš ï¸ PROTOTYPE/WORK IN PROGRESS** - This document outlines a proposed solution. Feedback welcome!

---

## The Problem

UCLA researchers need AWS access for computationally intensive research, but face critical challenges:

- **Security incidents**: Exposed credentials, misconfigured S3 buckets, unencrypted sensitive data
- **Compliance gaps**: HIPAA, CUI, FERPA, and UC data classification (P1-P4) violations
- **Cost overruns**: Forgotten instances, orphaned resources, lack of budget controls
- **Training disconnect**: Generic AWS training doesn't translate to research workflows
- **Support burden**: Repetitive questions, preventable mistakes, reactive firefighting

**Current approach**: Separate training courses + generic AWS tools = knowledge doesn't transfer to practice.

---

## The Solution: Training-as-Tool

**Ark** is a unified command-line tool that simultaneously trains researchers and provides production security tooling.

### How It Works: First-Time User Experience

**Scenario**: A new researcher receives notification that their UCLA AWS account is ready.

**Prerequisites**: 
- macOS, Linux, or Windows computer
- Internet connection for initial setup
- AWS CLI v2.15+ (Ark will help install if missing)

#### Step 1: Installation (2 minutes)

```bash
$ curl -sSL https://ark.ucla.edu/install.sh | bash

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸš€ Installing Ark - AWS Research Kit                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â†’ Detecting system... macOS (arm64)
â†’ Downloading ark v1.2.0... âœ“
â†’ Installing to /usr/local/bin/ark... âœ“

âœ… Ark installed successfully!

Next: ark init --institution ucla
```

#### Step 2: Configuration (5 minutes)

```bash
$ ark init --institution ucla

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“ UCLA AWS Research Tool Setup                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â†’ Loading UCLA configuration...
  âœ“ Configuration loaded

â†’ Required training modules:
  1. AWS Basics for Researchers (35 min)
  2. IAM & Identity Management (25 min)
  3. UC Data Classification (P1-P4) (25 min)
  4. S3 Storage Security (35 min)
  
  ğŸ“š Total: ~120 minutes (can pause and resume)

â†’ Downloading training content... âœ“

Next: ark setup wizard
```

#### Step 3: AWS Authentication (3 minutes)

```bash
$ ark setup wizard

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ” AWS Authentication Setup                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Let's connect you to UCLA's AWS environment.

â†’ Checking AWS CLI... âœ“ AWS CLI v2.15.2 detected

ğŸ“– You'll log in with your UCLA credentials + DUO (two-factor authentication).
   Uses SSO (Single Sign-On) - no API keys to manage. More secure!

Ready? [Y/n]: y

â†’ Executing: aws login

Opening browser for authentication...
[Browser opens for UCLA SSO login with DUO]

âœ… Authentication successful!

Account: 123456789012 (UCLA Research)
User: sarah.chen@ucla.edu

Would you like to start training now? [Y/n]: y
```

#### Step 4: Training-as-You-Go

Ark uses **progressive training** - you only complete modules when you need them for specific operations.

Basic AWS commands trigger Module 1, but creating storage buckets requires understanding data classification (Module 3) and storage security (Module 4) first. Module 2 (IAM) becomes required when managing users and permissions.

After basic setup, when the researcher tries to create a storage bucket:

```bash
# Example: Trying to create a bucket for internal research data
# (Note: P2 = "Internal" classification - you'll learn this in Module 3)
$ ark bucket create --name my-research-data --classification P2

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“ Training Required                                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Before creating buckets, complete:                       â•‘
â•‘    â€¢ Module 3: UC Data Classification (25 min)           â•‘
â•‘    â€¢ Module 4: S3 Storage Security (35 min)              â•‘
â•‘                                                           â•‘
â•‘  You'll learn this command while completing training!     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Start Module 3 now? [Y/n]: y
```

**After training**, the command executes with built-in security controls:
- âœ“ Encryption at rest (AES-256)
- âœ“ Encryption in transit (TLS 1.3)
- âœ“ Versioning and access logging
- âœ“ Block all public access
- âœ“ Cost monitoring enabled

**Key insight**: Training isn't a separate hurdle - it's embedded in the workflow. Researchers learn by doing, using the actual production tool.

**ğŸ“– Complete Journey**: See Appendix A for a detailed day-in-the-life walkthrough following Dr. Sarah Chen from installation through productive AWS usage (includes all training modules totaling ~2 hours, real commands, troubleshooting, and week 2 self-sufficiency). See Appendix B for module template structure and customization options.

---

## Key Features

### ğŸ“ **Progressive Training**
- Just-in-time learning when attempting new operations
- Interactive tutorials embedded in actual commands
- Quiz checkpoints ensure comprehension
- Completion tracking and certification generation (PDF certificates with cryptographic proof, recognized by institutional compliance offices for audit purposes)

### ğŸ”’ **Built-in Compliance**
- UC P1-P4 data classification validation
- HIPAA, CUI, FERPA requirement enforcement
- Pre-approved policy templates
- Automatic security best practices

### ğŸ›¡ï¸ **Bulletproof Operations**
- Automatic retry with exponential backoff
- Handles AWS eventual consistency
- Transaction rollback on failures
- Idempotent operations (safe to re-run)

### ğŸ’° **Cost Protection**
- Mandatory billing alerts
- Auto-shutdown for compute instances
- Orphaned resource detection
- Budget enforcement hooks

### ğŸ“Š **Institutional Oversight**
- Centralized completion tracking
- Security posture dashboards
- Audit trail integration with CloudTrail
- Customizable training content per department

---

## Implementation Approach

### Phase 1: Core Tool (Months 1-2)
- IAM user/group management with MFA enforcement
- S3 bucket creation with classification-based security
- EC2 instance lifecycle management
- Cost monitoring and alerting

### Phase 2: Training Integration (Months 2-3)
- 4 required modules (AWS basics, IAM, data classification, S3 security)
- Interactive checkpoints and quizzes
- Completion verification system
- Certificate generation

### Phase 3: Institutional Deployment (Month 4)
- UCLA-specific configuration (SSO, policies, support contacts)
- Integration with existing identity management
- Training content customization for departments
- Admin dashboards and reporting

---

## Benefits

### For Researchers
âœ“ **One tool to learn** - Training and production tooling unified  
âœ“ **Faster onboarding** - 2 hours to full AWS competency (vs weeks with traditional training)  
âœ“ **Confidence** - Can't make critical security mistakes (built-in guardrails)  
âœ“ **Self-service** - Standard operations (buckets, instances, databases) don't require approval
   (Note: P4 data and specialized resources still require institutional review)

### For IT Security
âœ“ **Enforced compliance** - Can't skip security controls  
âœ“ **Reduced incidents** - Built-in guardrails prevent common mistakes (target: 80% reduction)  
âœ“ **Audit trails** - Complete logging of training and operations  
âœ“ **Scalable** - Minimal support burden as researchers self-serve

### For UCLA
âœ“ **Risk reduction** - Systematic security control enforcement  
âœ“ **Cost control** - Automated budget monitoring and alerting (reduce unexpected costs by 90%, save ~$200k/year in support)  
âœ“ **Compliance** - Demonstrable training and audit trails for regulators  
âœ“ **Competitive advantage** - Enables cutting-edge research safely

---

## Technology

- **Language**: Go (single binary, cross-platform, fast)
- **AWS SDK**: Official AWS SDK v2 for Go
- **Distribution**: GitHub releases, institutional package repos
- **Configuration**: YAML-based, remotely updatable training content
- **Authentication**: AWS SSO with new `aws login` command support

---

## Success Metrics

**Measurement Period**: Evaluated at 6 and 12 months post-deployment  
**Baseline**: 6 months prior to Ark deployment  
**Reporting**: Ongoing dashboard with quarterly reviews

- **Training completion rate**: Target 95% within 30 days of AWS access
- **Security incidents**: Reduce by 80% compared to baseline
- **Cost incidents**: Reduce surprise bills >$1000 by 90%
- **Support tickets**: Reduce AWS-related tickets by 60%
- **Time to productivity**: <2 hours from account creation to first resource deployed

---

## Next Steps

1. **Pilot program** with 2-3 research labs (Month 1)
   - Owner: IT Security Team with Solutions Architecture support
   - Target: 50-100 users
2. **Refinement** based on researcher feedback (Month 2)
   - Owner: Product team + CISO Office
3. **Broader rollout** to departments with AWS needs (Month 3-4)
   - Owner: IT Leadership
4. **Mandatory requirement** for new AWS account requests (Month 5+)
   - Owner: Institutional Policy

---

## Appendix A: First-Time User Walkthrough

### Scenario: Dr. Sarah Chen, Postdoc in Computational Biology

**Background**: Sarah needs to analyze 500GB of genomic data. She's comfortable with Python and the command line but has never used AWS. Her PI just got her an AWS account through UCLA.

---

### Day 1, 9:00 AM - Installation

Sarah receives an email from IT:

> Your UCLA AWS account is ready!  
> Install Ark to get started: https://ark.ucla.edu/install

```bash
$ curl -sSL https://ark.ucla.edu/install.sh | bash

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸš€ Installing Ark - AWS Research Kit                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â†’ Detecting system... macOS (arm64)
â†’ Checking for AWS CLI... Not found
  Installing AWS CLI v2.15.2... âœ“
â†’ Downloading ark v1.2.0... âœ“
â†’ Installing to /usr/local/bin/ark... âœ“
â†’ Verifying installation... âœ“

âœ… Ark installed successfully!

Next steps:
  1. Run: ark init --institution ucla
  2. Complete setup: ark setup wizard
  3. Start training: ark learn start

Need help? Visit https://ark.ucla.edu/docs
```

---

### 9:02 AM - Initial Configuration

```bash
$ ark init --institution ucla

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“ UCLA AWS Research Tool Setup                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â†’ Loading UCLA configuration...
  ğŸ“¥ Downloading from: https://ucla-aws-training.s3.amazonaws.com/config/ucla.yaml
  âœ“ Configuration loaded

Institution: UCLA
Support Email: your institutional AWS support
Documentation: https://it.ucla.edu/aws

â†’ Required training modules:
  1. AWS Basics for Researchers (35 min)
  2. IAM & Identity Management (25 min)
  3. UC Data Classification (P1-P4) (25 min)
  4. S3 Storage Security (35 min)
  
  ğŸ“š Total estimated time: 120 minutes
  ğŸ’¡ You can pause and resume anytime!

â†’ Downloading training content...
  Module 1/4: AWS Basics... âœ“
  Module 2/4: IAM & Identity... âœ“
  Module 3/4: Data Classification... âœ“
  Module 4/4: S3 Security... âœ“

âœ… Setup complete!

Your Progress: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0/4 modules (0%)

Next: ark setup wizard
```

---

### 9:05 AM - AWS Authentication Setup

```bash
$ ark setup wizard

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ” AWS Authentication Setup                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Let's connect you to UCLA's AWS environment.

â†’ Checking AWS CLI installation...
  âœ“ AWS CLI v2.15.2 detected
  âœ“ Supports new 'aws login' command

ğŸ“– About AWS Single Sign-On (SSO)
   You'll log in with your UCLA credentials + DUO (two-factor authentication).
   No API keys to manage - more secure and simpler!
   
   The new 'aws login' command (AWS CLI v2.15+) simplifies
   authentication compared to the older 'aws sso login' method.

Ready to authenticate? [Y/n]: y

â†’ Executing: aws login

Opening your browser to authenticate...
  ğŸŒ https://ucla.awsapps.com/start

[Browser opens, Sarah logs in with UCLA credentials and DUO]
[After successful login, browser shows: "You may now close this window"]

â†’ Waiting for authentication... âœ“

âœ… Authentication successful!

â†’ Verifying credentials...
  Account: 123456789012 (UCLA Research)
  User: AIDAI...XYZ (sarah.chen@ucla.edu)
  âœ“ Credentials verified

â†’ Checking your permissions...
  âœ“ S3 access: Read/Write
  âœ“ EC2 access: Launch instances
  âœ“ IAM access: Limited (read-only)
  âœ“ Cost Explorer: View own usage

ğŸ’¡ Your permissions follow the "UCLA Researcher" policy.
   This gives you access to core services while maintaining security.

âœ… All systems ready!

Would you like to start training now? [Y/n]: y
```

---

### 9:10 AM - Module 1: AWS Basics

```bash
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“š Module 1: AWS Basics for Researchers                     â•‘
â•‘  Duration: ~35 minutes                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Welcome, Sarah! ğŸ‘‹

This module covers:
  â€¢ What is AWS and why researchers use it
  â€¢ Key services: S3 (storage), EC2 (computing), IAM (security)
  â€¢ UCLA's AWS setup and support resources
  â€¢ How costs work and how to avoid surprises
  â€¢ **CRITICAL: Common security threats and how to prevent them**

Press ENTER to begin...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Section 1.1: What is AWS?

AWS (Amazon Web Services) is like renting lab equipment, but for computing.
Instead of buying servers, you rent what you need, when you need it.

Why researchers love AWS:
  âœ“ Scale up for big analyses, scale down when done
  âœ“ Pay only for what you use
  âœ“ Access to powerful GPUs without buying hardware
  âœ“ Collaborate by sharing data securely
  âœ“ 99.99% uptime - more reliable than local servers

Real UCLA example:
  Dr. Martinez (Neuroscience) analyzed 10TB of fMRI data using 
  100 EC2 instances for 8 hours. Cost: $240. 
  
  Buying equivalent hardware: ~$50,000 + maintenance.

Press ENTER to continue...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Section 1.2: Security First - Why This Matters

ğŸš¨ REAL INCIDENTS FROM ACADEMIC INSTITUTIONS (2023-2024):

âŒ Incident 1: Public S3 Bucket
   University: Major Research Institution (anonymized)
   What happened: Researcher made bucket public to "share with collaborator"
   Result: 2TB of patient genomic data exposed for 6 months
   Impact: $4.2M HIPAA fine, IRB suspension, lawsuits
   
   Prevention: Ark BLOCKS public access by default for sensitive data

âŒ Incident 2: Exposed AWS Keys in GitHub
   University: West Coast R1 Institution
   What happened: Student committed AWS keys to public GitHub repo
   Result: Cryptominers used account, $62,000 bill in 3 days
   Impact: Lab funding exhausted, student's PhD delayed
   
   Prevention: Ark uses SSO - no long-term keys to expose

âŒ Incident 3: Forgotten EC2 Instance
   University: Midwest Research Lab
   What happened: Postdoc left institution, instance kept running
   Result: $18,000 over 14 months, GPUs sitting idle
   Impact: PI had to return grant funds to cover costs
   
   Prevention: Ark requires auto-shutdown configuration

âš ï¸  These aren't rare - they happen weekly across academia.

ğŸ›¡ï¸  YOUR RESPONSIBILITY:
   As a researcher with AWS access, you are:
   â€¢ A steward of sensitive research data
   â€¢ A guardian of lab/grant funding
   â€¢ A representative of UCLA's security posture
   
   This training ensures you don't become a cautionary tale.

Press ENTER to continue...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Section 1.3: The Shared Responsibility Model

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AWS Responsibility                    â”‚
â”‚  (Security OF the cloud)                        â”‚
â”‚                                                 â”‚
â”‚  â€¢ Physical data centers                        â”‚
â”‚  â€¢ Hardware infrastructure                      â”‚
â”‚  â€¢ Network infrastructure                       â”‚
â”‚  â€¢ Virtualization layer                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          YOUR Responsibility                    â”‚
â”‚  (Security IN the cloud)                        â”‚
â”‚                                                 â”‚
â”‚  â€¢ Data encryption â† YOU must enable            â”‚
â”‚  â€¢ Access controls â† YOU must configure         â”‚
â”‚  â€¢ Credential management â† YOU must protect     â”‚
â”‚  â€¢ Network configuration â† YOU must secure      â”‚
â”‚  â€¢ Cost management â† YOU must monitor           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Think of it like a safe deposit box:
  â€¢ Bank secures the building (AWS's job)
  â€¢ You must lock your box and guard your key (YOUR job)

Ark helps you fulfill YOUR responsibilities correctly.

Press ENTER to continue...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Section 1.4: Core AWS Services

Think of AWS services as tools in a toolkit:

ğŸ—„ï¸  S3 (Simple Storage Service)
   Like Dropbox, but for research data.
   â€¢ Store files from bytes to terabytes
   â€¢ Automatic redundancy (your data is safe)
   â€¢ Access from anywhere
   
   Example: Store your genomic sequence files
   
   ğŸš¨ Security consideration:
      Default S3 buckets are PRIVATE, but one wrong setting
      makes them PUBLIC. Ark prevents this mistake.

ğŸ’» EC2 (Elastic Compute Cloud)
   Rent virtual computers by the hour.
   â€¢ From small (2 CPUs) to huge (hundreds of CPUs)
   â€¢ GPU instances for machine learning
   â€¢ Run any software you need
   
   Example: Process 500GB of data in parallel
   
   ğŸš¨ Security consideration:
      Forgotten instances = wasted money. Always set auto-shutdown.

ğŸ” IAM (Identity & Access Management)
   Control who can access what.
   â€¢ Create users for lab members
   â€¢ Set permissions carefully
   â€¢ Enable multi-factor authentication
   
   Example: Give your student read-only access to data
   
   ğŸš¨ Security consideration:
      Over-privileged users = biggest risk. Follow "least privilege."

ğŸ“Š CloudWatch
   Monitor costs and usage.
   â€¢ Set billing alarms
   â€¢ Track resource usage
   â€¢ Get alerts before overspending
   
   ğŸš¨ Security consideration:
      You MUST set billing alarms - treat it like a fume hood alarm.

Press ENTER to continue...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Section 1.5: The 5 Golden Rules of AWS Security

Remember these ALWAYS:

1ï¸âƒ£  NEVER share credentials
   â€¢ Not with lab mates
   â€¢ Not via email
   â€¢ Not in Slack/Teams
   â€¢ Not in code repositories
   
   If someone needs access â†’ Create them an account

2ï¸âƒ£  ALWAYS enable MFA (multi-factor authentication)
   â€¢ Prevents 99.9% of account compromises
   â€¢ Takes 2 minutes to set up
   â€¢ Required by UCLA policy
   
   Your password alone is NOT enough

3ï¸âƒ£  ENCRYPT everything sensitive
   â€¢ P3/P4 data MUST be encrypted
   â€¢ Encryption at rest + in transit
   â€¢ Don't assume it's automatic
   
   Ark handles this for you when you classify correctly

4ï¸âƒ£  MONITOR your costs daily
   â€¢ Set billing alarms FIRST
   â€¢ Check costs at end of each day
   â€¢ Investigate unusual spikes immediately
   
   Financial responsibility = security responsibility

5ï¸âƒ£  AUDIT regularly
   â€¢ What resources are running?
   â€¢ Who has access to what?
   â€¢ Are security settings still correct?
   
   Use: ark audit scan (weekly recommended)

These aren't suggestions - they're requirements.

Press ENTER to continue...

[Training continues through sections on costs, billing, support...]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ Checkpoint Quiz

Let's check your understanding!

Q1: What's the main advantage of AWS for researchers?
  a) It's free
  b) Pay for what you use, scale as needed
  c) Faster than local computers
  d) Automatic data analysis

Your answer: b

âœ… Correct! The elasticity and pay-as-you-go model means you can 
   access massive compute resources without capital investment.

Q2: Which service would you use to store 200GB of sequencing data?
  a) EC2
  b) IAM
  c) S3
  d) CloudWatch

Your answer: c

âœ… Exactly! S3 is designed for data storage at any scale.

Q3: What should you set up to avoid surprise AWS bills?
  a) CloudWatch billing alarms
  b) Nothing - AWS is always cheap
  c) Automatic shutdowns only
  d) IAM policies

Your answer: a

âœ… Perfect! Always set billing alarms before using AWS.

Q4: ğŸ”’ SECURITY QUESTION: You need to share AWS access with a 
    visiting collaborator. What should you do?

  a) Share your username and password
  b) Create them their own IAM user account
  c) Give them your laptop
  d) Email them your access keys

Your answer: b

âœ… CORRECT! Never share credentials. Always create separate accounts.
   This ensures:
   â€¢ Accountability (know who did what)
   â€¢ Revocable access (can remove when they leave)
   â€¢ Audit trails (CloudTrail logs their actions)

Q5: ğŸ”’ SECURITY QUESTION: You find your AWS access key accidentally
    committed to a public GitHub repo. What do you do?

  a) Delete the GitHub commit and hope no one saw it
  b) Immediately rotate the key and contact security
  c) Wait and see if anything bad happens
  d) Change your GitHub password

Your answer: b

âœ… CRITICAL! Exposed keys = compromised account. Always:
   1. Rotate keys immediately (Ark will help)
   2. Contact your institutional AWS support
   3. Check CloudTrail for unauthorized usage
   4. Document the incident
   
   Keys can be scraped in minutes by bots.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ Hands-On Exercise: Set Up Your First Security Control

Now let's actually set up a billing alarm!

This is a real operation - we'll create an actual alarm on your account.

Why this matters:
  ğŸ’° Prevents cost overruns
  ğŸš¨ Early warning system
  ğŸ“§ Alerts you before problems grow

â†’ Creating billing alarm...
  Name: sarah-chen-monthly-budget
  Threshold: $100/month
  Alert: sarah.chen@ucla.edu

Execute this operation? [Y/n]: y

â†’ Calling AWS CloudWatch API...
  âœ“ Alarm created

â†’ Sending test notification...
  âœ“ Check your email for confirmation

ğŸ’¡ You'll receive an email if spending exceeds $100/month.
   Adjust anytime with: ark cost alert update
   
   ğŸ”’ Security tip: Set alarms at multiple thresholds:
      â€¢ $50 - Advisory notice
      â€¢ $100 - Warning
      â€¢ $200 - Critical alert

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Module 1 Complete!

Time: 35 minutes
Score: 100% (5/5 correct)

ğŸ”’ Security Concepts Learned:
  âœ“ Shared responsibility model
  âœ“ Real-world incident examples
  âœ“ The 5 Golden Rules
  âœ“ Credential protection
  âœ“ Incident response basics

Progress: â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 1/4 modules (25%)

Commands Unlocked:
  âœ“ ark cost alert    - Manage billing alerts
  âœ“ ark cost report   - View spending breakdown
  âœ“ ark audit basics  - Check account security

Continue to Module 2: IAM & Identity Management? [Y/n]: n

No problem! Resume anytime with: ark learn continue

Your progress is saved automatically.
```

---

### 9:45 AM - Sarah Takes a Coffee Break

She's learned the basics and completed the security foundations. Now she wants to actually upload her genomic data.

---

### 9:50 AM - Trying to Use S3 (Training Gate)

```bash
$ ark bucket create --name sarah-genomics-data --classification P2

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âš ï¸  Training Required                                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Before creating S3 buckets, you must complete:             â•‘
â•‘                                                              â•‘
â•‘  Module 3: UC Data Classification ................ âœ—         â•‘
â•‘    (~15 min - learn P1-P4 levels)                            â•‘
â•‘                                                              â•‘
â•‘  Module 4: S3 Storage Security ................... âœ—         â•‘
â•‘    (~30 min - encryption, access control)                    â•‘
â•‘                                                              â•‘
â•‘  Why? Creating buckets incorrectly is a top security risk.  â•‘
â•‘  These modules ensure you protect your research data.        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Start Module 3 now? [Y/n]: y
```

---

### 10:00 AM - Module 3: UC Data Classification

```bash
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“š Module 3: UC Data Classification (P1-P4)                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Understanding data sensitivity is CRITICAL for compliance and security.

âš ï¸  Getting this wrong has serious consequences:
   â€¢ Federal fines ($100k - $50M+ per incident)
   â€¢ Loss of grant funding
   â€¢ IRB suspension
   â€¢ Legal liability
   â€¢ Reputational damage to UCLA

This module ensures you classify and protect data correctly.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

UC Protection Levels - The Framework:

UCLA follows University of California data protection standards.
Every piece of data falls into one of four categories:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ P1 - PUBLIC INFORMATION                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ What: Information intended for public distribution          â”‚
â”‚                                                             â”‚
â”‚ Examples:                                                   â”‚
â”‚   âœ“ Published research papers                              â”‚
â”‚   âœ“ Public course catalogs                                 â”‚
â”‚   âœ“ Campus directory information                           â”‚
â”‚   âœ“ Marketing materials                                    â”‚
â”‚                                                             â”‚
â”‚ Requirements: None (already public)                         â”‚
â”‚ AWS: Standard S3, no special controls needed               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ P2 - INTERNAL INFORMATION                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ What: Information for UCLA use only                         â”‚
â”‚                                                             â”‚
â”‚ Examples:                                                   â”‚
â”‚   âœ“ Unpublished research data (no PII)                     â”‚
â”‚   âœ“ Grant proposals (pre-submission)                       â”‚
â”‚   âœ“ Internal reports and memos                             â”‚
â”‚   âœ“ Non-sensitive lab data                                 â”‚
â”‚                                                             â”‚
â”‚ Requirements:                                               â”‚
â”‚   â€¢ Access limited to UCLA affiliates                      â”‚
â”‚   â€¢ Basic access controls                                  â”‚
â”‚   â€¢ Encryption recommended but not required                â”‚
â”‚                                                             â”‚
â”‚ AWS: Private S3 bucket, encryption enabled                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ P3 - PROTECTED INFORMATION  â† MOST COMMON FOR RESEARCH      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ What: Sensitive data requiring protection                   â”‚
â”‚                                                             â”‚
â”‚ Examples:                                                   â”‚
â”‚   âœ“ Personal Identifiable Information (PII)                â”‚
â”‚     - Names, addresses, phone numbers                      â”‚
â”‚     - Email addresses, student IDs                         â”‚
â”‚     - Birth dates, driver's license numbers                â”‚
â”‚   âœ“ Student records (FERPA protected)                      â”‚
â”‚   âœ“ De-identified health data (not full PHI)              â”‚
â”‚   âœ“ Research data with confidentiality agreements          â”‚
â”‚   âœ“ Export-controlled research data                        â”‚
â”‚   âœ“ Proprietary business information                       â”‚
â”‚                                                             â”‚
â”‚ Legal Frameworks:                                           â”‚
â”‚   â€¢ FERPA (Family Educational Rights and Privacy Act)      â”‚
â”‚   â€¢ PII protection laws (CCPA, GDPR if applicable)         â”‚
â”‚   â€¢ Contractual confidentiality obligations                â”‚
â”‚                                                             â”‚
â”‚ Requirements:                                               â”‚
â”‚   â€¢ âœ“ Encryption at rest (REQUIRED)                        â”‚
â”‚   â€¢ âœ“ Encryption in transit (REQUIRED)                     â”‚
â”‚   â€¢ âœ“ Access logging for audits                            â”‚
â”‚   â€¢ âœ“ Strong access controls                               â”‚
â”‚   â€¢ âœ“ MFA for administrators                               â”‚
â”‚   â€¢ âœ“ Incident response plan                               â”‚
â”‚   â€¢ âœ“ Regular access reviews                               â”‚
â”‚                                                             â”‚
â”‚ AWS: Ark P3 configuration enforces ALL requirements         â”‚
â”‚                                                             â”‚
â”‚ ğŸš¨ Common Mistake: "It's de-identified so it's fine"       â”‚
â”‚    Even de-identified data can often be re-identified!     â”‚
â”‚    When in doubt, treat as P3.                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ P4 - HIGHLY RESTRICTED INFORMATION                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ What: Extremely sensitive data with strict regulations      â”‚
â”‚                                                             â”‚
â”‚ Examples:                                                   â”‚
â”‚   âœ“ Protected Health Information (PHI) - HIPAA            â”‚
â”‚   âœ“ Social Security Numbers                               â”‚
â”‚   âœ“ Financial account numbers                             â”‚
â”‚   âœ“ Controlled Unclassified Information (CUI)             â”‚
â”‚   âœ“ ITAR/EAR controlled technical data                    â”‚
â”‚   âœ“ Credit card numbers (PCI DSS)                         â”‚
â”‚                                                             â”‚
â”‚ Legal Frameworks:                                           â”‚
â”‚   â€¢ HIPAA (Health Insurance Portability Act)               â”‚
â”‚   â€¢ NIST 800-171 (CUI protection)                          â”‚
â”‚   â€¢ CMMC (DoD cybersecurity)                               â”‚
â”‚   â€¢ ITAR (International Traffic in Arms)                   â”‚
â”‚   â€¢ PCI DSS (Payment Card Industry)                        â”‚
â”‚                                                             â”‚
â”‚ Requirements:                                               â”‚
â”‚   â€¢ âœ“ All P3 requirements PLUS:                            â”‚
â”‚   â€¢ âœ“ Pre-approved AWS account configuration               â”‚
â”‚   â€¢ âœ“ Business Associate Agreement (BAA) for HIPAA        â”‚
â”‚   â€¢ âœ“ Enhanced monitoring and alerting                     â”‚
â”‚   â€¢ âœ“ Dedicated security review                            â”‚
â”‚   â€¢ âœ“ Compliance officer approval                          â”‚
â”‚   â€¢ âœ“ Annual audits                                        â”‚
â”‚   â€¢ âœ“ Incident notification within 24-72 hours            â”‚
â”‚                                                             â”‚
â”‚ AWS: Requires CISO office approval BEFORE use               â”‚
â”‚      Contact: your institutional HIPAA compliance office                     â”‚
â”‚                                                             â”‚
â”‚ âš ï¸  DO NOT store P4 data without explicit approval!        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”’ REAL WORLD: Classification Failures

Case Study 1: The "Anonymous" Survey
  âœ— Scenario: Researcher collected "anonymous" health surveys
  âœ— Reality: Included zip code + age + gender
  âœ— Problem: This combination can identify ~87% of US population
  âœ— Classification error: Treated as P2, actually P3 (maybe P4!)
  âœ— Consequence: Data breach notification to 1,200 participants
  
  Lesson: Combinations of "non-sensitive" data = sensitive data

Case Study 2: The Collaboration Mistake  
  âœ— Scenario: Shared student performance data with external partner
  âœ— Reality: Didn't get data sharing agreement
  âœ— Problem: FERPA violation (student data improperly disclosed)
  âœ— Consequence: $50,000 fine, IRB investigation
  
  Lesson: P3 data sharing requires agreements, even with collaborators

Case Study 3: The De-identification Assumption
  âœ— Scenario: Published "de-identified" genomic sequences
  âœ— Reality: Sequences + public genealogy DB = re-identification
  âœ— Problem: Participants identified, privacy violated
  âœ— Consequence: Study retracted, lawsuits filed
  
  Lesson: De-identification is harder than you think

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ Decision Tree: When In Doubt

Start here: Does your data contain ANY of the following?

  â”Œâ”€ Names, email addresses, phone numbers?
  â”‚  â””â”€ YES â†’ At least P3
  â”‚
  â”Œâ”€ Student records or grades?
  â”‚  â””â”€ YES â†’ P3 (FERPA applies)
  â”‚
  â”Œâ”€ Health information (even de-identified)?
  â”‚  â””â”€ YES â†’ At least P3, possibly P4 if identifiable
  â”‚
  â”Œâ”€ Financial data, SSNs, credit cards?
  â”‚  â””â”€ YES â†’ P4 (stop, contact CISO office)
  â”‚
  â”Œâ”€ Under confidentiality agreement?
  â”‚  â””â”€ YES â†’ Read agreement, probably P3
  â”‚
  â”Œâ”€ Export controlled (ITAR/EAR)?
  â”‚  â””â”€ YES â†’ P4 (stop, contact export control office)
  â”‚
  â”Œâ”€ Will be published/public eventually?
  â”‚  â””â”€ YES but not yet â†’ P2 until published
  â”‚
  â””â”€ None of the above?
     â””â”€ Probably P1 or P2, but verify with PI

ğŸ†˜ Still unsure? That's OK!
   Contact: your institutional data classification office
   They'll help you classify correctly (better safe than sorry)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ Interactive Exercise: Classify Sarah's Data

Your research scenario:
  â€¢ Genomic sequences from Drosophila (fruit flies)
  â€¢ No human subjects
  â€¢ No personally identifiable information
  â€¢ Funded by NSF grant
  â€¢ Will be published when analysis complete
  â€¢ No confidentiality agreements

What classification level? [P1/P2/P3/P4]: P2

âœ… Correct! This is P2 (Internal) because:
   â€¢ Not yet published (so not P1)
   â€¢ No PII or regulated data (so not P3/P4)
   â€¢ Internal research data until publication
   â€¢ Non-human subject research

When you publish, you can reclassify to P1.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ Checkpoint Quiz (Higher Stakes)

Q1: You have a dataset with: age (binned in 5-year ranges), 
    zip code, and diagnosis. No names. What level?

  a) P1 - It's de-identified
  b) P2 - Internal use only
  c) P3 - Can be re-identified
  d) P4 - Contains health info

Your answer: c

âœ… CORRECT! Even without names, this is P3 because:
   â€¢ Age + zip code + diagnosis = potentially identifiable
   â€¢ Health information requires protection even when de-identified
   â€¢ Could violate HIPAA if re-identified
   
   This is called "quasi-identifiers" - seemingly anonymous
   data that can be combined to identify individuals.

Q2: Your collaborator at Stanford needs access to your 
    P3 research data. What do you need?

  a) Just share an S3 link
  b) Data sharing agreement + BAA if needed
  c) Their email address
  d) Nothing special - they're at a university

Your answer: b

âœ… PERFECT! For P3 data sharing, you need:
   1. Data Sharing Agreement (legal framework)
   2. Business Associate Agreement if health data (HIPAA)
   3. Document what data is shared and why
   4. Time-limited access (not permanent)
   5. UCLA IRB approval if human subjects
   
   Contact: your institutional data sharing office for templates

Q3: ğŸš¨ COMPLIANCE SCENARIO: You discover you've been storing
    what you thought was P2 data, but it actually contains 
    email addresses (P3). What do you do?

  a) Delete the emails and move on
  b) Immediately report to CISO, re-classify, audit access
  c) Just fix it going forward
  d) Hope no one noticed

Your answer: b

âœ… CRITICAL! When you discover a classification error:
   
   IMMEDIATE actions:
   1. Stop any current data sharing
   2. Email: your institutional security incident response team
   3. Document: What data? How long misclassified? Who had access?
   
   CISO will help you:
   â€¢ Re-classify correctly
   â€¢ Audit who accessed the data
   â€¢ Implement proper controls
   â€¢ Determine if breach notification needed
   
   ğŸ¯ Key principle: It's never wrong to report. It IS wrong to hide.

Q4: Can you mix P2 and P3 data in the same S3 bucket?

  a) Yes, it's fine
  b) Yes, but separate folders
  c) No, always use separate buckets
  d) Only with special permission

Your answer: c

âœ… CORRECT! Best practice: Separate buckets per classification.
   
   Why?
   â€¢ Bucket-level encryption settings differ
   â€¢ Access controls are simpler
   â€¢ Audit logging is clearer
   â€¢ Reduces accidental exposure risk
   â€¢ Compliance audits are easier
   
   If you MUST mix (rare cases):
   â€¢ Get CISO approval
   â€¢ Use highest classification's controls (P3)
   â€¢ Document exception clearly
   â€¢ More frequent audits required

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ UCLA Data Classification Quick Reference

Save this! You'll need it.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Question â”‚     P1     â”‚     P2      â”‚      P3      â”‚      P4      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Contains â”‚ None       â”‚ None        â”‚ Names, email â”‚ SSN, PHI,    â”‚
â”‚ PII?     â”‚            â”‚             â”‚ phone, DOB   â”‚ financials   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Encrypt  â”‚ Optional   â”‚ Recommended â”‚ REQUIRED     â”‚ REQUIRED +   â”‚
â”‚ at rest? â”‚            â”‚             â”‚              â”‚ key mgmt     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Access   â”‚ Public     â”‚ UCLA only   â”‚ Authorized   â”‚ Minimal,     â”‚
â”‚ control? â”‚            â”‚             â”‚ users only   â”‚ documented   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Logging  â”‚ Optional   â”‚ Recommended â”‚ REQUIRED     â”‚ REQUIRED +   â”‚
â”‚ required?â”‚            â”‚             â”‚              â”‚ monitoring   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Breach   â”‚ None       â”‚ CISO notice â”‚ CISO + OCR   â”‚ CISO + OCR   â”‚
â”‚ notify?  â”‚            â”‚             â”‚ if PII       â”‚ within 72h   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ UCLA     â”‚ None       â”‚ None        â”‚ Training     â”‚ CISO pre-    â”‚
â”‚ approval?â”‚            â”‚             â”‚ + compliance â”‚ approval     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Download full guide: ark classify --download-guide

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Module 3 Complete! (25 minutes)

ğŸ”’ Security Concepts Learned:
  âœ“ UC P1-P4 classification framework
  âœ“ Legal frameworks (FERPA, HIPAA, CUI)
  âœ“ Re-identification risks
  âœ“ Data sharing requirements
  âœ“ Incident response for classification errors
  âœ“ Compliance requirements per level

Progress: â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘ 2/4 modules (50%)

ğŸ“ You now understand UCLA's data protection standards!

Commands Unlocked:
  âœ“ ark classify --help    - Classification helper tool
  âœ“ ark bucket create      - Create buckets (with classification)

Continue to Module 4: S3 Storage Security? [Y/n]: y
```

---

### 10:30 AM - Module 4: S3 Storage Security

```bash
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“š Module 4: S3 Storage Security                            â•‘
â•‘  Duration: ~35 minutes                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

This module covers:
  â€¢ Encryption at rest and in transit
  â€¢ Bucket policies and access controls
  â€¢ Versioning and lifecycle management
  â€¢ Access logging and monitoring
  â€¢ Common misconfigurations and how to avoid them

[Sarah completes Module 4, learning about:]
  â€¢ S3 encryption options (SSE-S3, SSE-KMS, SSE-C)
  â€¢ How bucket policies differ from IAM policies
  â€¢ Setting up lifecycle rules to reduce costs
  â€¢ Enabling access logging for audit trails
  â€¢ Preventing accidental public exposure
  â€¢ MFA Delete for critical data

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Module 4 Complete! (35 minutes)

Progress: â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘ 3/4 modules (75%)

ğŸ”’ Security Concepts Learned:
  âœ“ S3 encryption methods and when to use each
  âœ“ Bucket policy design for least privilege
  âœ“ Lifecycle policies for cost optimization
  âœ“ Access logging configuration
  âœ“ Public access blocking (mandatory for P3/P4)
  âœ“ MFA Delete protection

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ‰ Great progress! You can now:
  âœ“ Create S3 buckets with proper security
  âœ“ Upload and manage research data
  âœ“ Control access for collaborators

Commands Unlocked:
  âœ“ ark bucket create
  âœ“ ark bucket upload
  âœ“ ark bucket share
  âœ“ ark bucket audit

**Note on Module 2 (IAM)**: Sarah hasn't completed the IAM & Identity Management module yet. This is intentional - she'll complete it later when she needs to create users for lab members or manage permissions. Progressive training means you learn what you need, when you need it.

Ready to create your bucket now? [Y/n]: y
```

---

### 11:10 AM - Creating Her First Bucket (For Real)

```bash
$ ark bucket create --name sarah-genomics-data --classification P2

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ—„ï¸  S3 Bucket Creation                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â†’ Validating bucket name...
  âœ“ Name is valid and available

â†’ Confirming classification: P2 (Internal Information)
  
  For P2 data, we'll configure:
    â€¢ âœ“ Encryption at rest (AES-256)
    â€¢ âœ“ TLS required for uploads
    â€¢ âœ“ Versioning (protects from accidents)
    â€¢ âœ“ Access logging
    â€¢ âœ“ Block public access
    â€¢ âœ— MFA delete (not required for P2)

  This configuration meets UCLA policy for P2 data.

Proceed? [Y/n]: y

â†’ Creating S3 bucket...
  â ‹ Calling S3 CreateBucket API...
  âœ“ Bucket created: sarah-genomics-data

â†’ Enabling encryption...
  â ™ Configuring AES-256-GCM...
  âœ“ Encryption enabled
  
  ğŸ’¡ Files are automatically encrypted when uploaded!

â†’ Enabling versioning...
  â ¹ Configuring version control...
  âœ“ Versioning enabled
  
  ğŸ’¡ Previous versions kept for 90 days (configurable)

â†’ Configuring access logging...
  â ¸ Creating audit log bucket...
  â ¼ Enabling logging...
  âœ“ Access logging enabled
  
  ğŸ’¡ All access is logged for security audits

â†’ Blocking public access...
  â § Applying block public access...
  âœ“ Public access blocked
  
  ğŸ’¡ This bucket is private - only you can access it

â†’ Setting lifecycle policy...
  â ‡ Transitioning old data to cheaper storage...
  âœ“ Lifecycle policy applied
  
  ğŸ’¡ Data >90 days old moves to Glacier (90% cheaper!)

â†’ Adding cost allocation tags...
  âœ“ Tagged: PI=chen-lab, Department=biology, Project=drosophila

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âœ… Bucket Created Successfully!                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Name: sarah-genomics-data                                   â•‘
â•‘  Classification: P2 (Internal)                               â•‘
â•‘  Region: us-west-2                                           â•‘
â•‘  Encryption: âœ“ | Versioning: âœ“ | Logging: âœ“                 â•‘
â•‘  Public Access: âœ— (Blocked)                                  â•‘
â•‘  Estimated Cost: ~$12/month for 500GB                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Next steps:

  1ï¸âƒ£  Upload your data:
     ark bucket upload --name sarah-genomics-data --file sequences.tar.gz
     
  2ï¸âƒ£  Share with collaborators:
     ark bucket share --name sarah-genomics-data --with colleague@ucla.edu
     
  3ï¸âƒ£  Monitor costs:
     ark cost report --bucket sarah-genomics-data

ğŸ“– Quick tips:
   â€¢ Upload large files (>100MB) in parts for reliability
   â€¢ Use folders to organize: sequences/, results/, metadata/
   â€¢ Set up notifications: ark bucket notify --on-upload

â±ï¸  Total time: 47 seconds
```

---

### 12:00 PM - Uploading Data

```bash
$ ark bucket upload --name sarah-genomics-data --file drosophila-sequences.tar.gz

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“¤ S3 Upload                                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

File: drosophila-sequences.tar.gz
Size: 487 GB
Destination: s3://sarah-genomics-data/

â†’ Analyzing file...
  âœ“ File is >100MB - will use multipart upload
  âœ“ Splitting into 1,000 parts of 500MB each

â†’ Starting upload...
  âš ï¸  This will take approximately 2.5 hours on your connection
  
  ğŸ’¡ You can close this terminal - upload will continue!
     Check status: ark bucket upload status

  Progress: â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 40% (195 GB / 487 GB)
  Speed: 21 MB/s
  ETA: 1h 52m
  
  Parts completed: 402/1000
  Failed/retrying: 3 (automatically retrying)

[Upload continues in background...]

âœ… Upload complete! (2h 18m)

â†’ Verifying upload integrity...
  âœ“ All parts uploaded successfully
  âœ“ File checksum matches

Your data is now securely stored and encrypted in AWS!

Access: s3://sarah-genomics-data/drosophila-sequences.tar.gz
URL: https://sarah-genomics-data.s3.us-west-2.amazonaws.com/...

Estimated monthly cost: $11.80 (based on 487GB + 10% growth)
```

---

### Day 2 - Sarah Needs Compute

```bash
$ ark instance launch --type m5.xlarge --purpose "Sequence alignment"

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âš ï¸  Training Required                                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Before launching EC2 instances, complete:                   â•‘
â•‘                                                              â•‘
â•‘  Module 5: Compute Security & Cost Control ...... âœ—          â•‘
â•‘    (~25 min)                                                 â•‘
â•‘                                                              â•‘
â•‘  This module covers:                                         â•‘
â•‘    â€¢ Choosing the right instance type                        â•‘
â•‘    â€¢ Auto-shutdown to prevent waste                          â•‘
â•‘    â€¢ Security groups and network access                      â•‘
â•‘    â€¢ Monitoring and cost optimization                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Start Module 5 now? [Y/n]: y

[Sarah completes Module 5 - 23 minutes]

âœ… All Training Complete! ğŸ‰

Progress: â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ 4/4 modules (100%)

Total time: 88 minutes
Overall score: 97%

Generating certificate...
âœ“ Certificate saved: ~/Downloads/ucla-aws-training-sarah-chen.pdf

You now have full access to all Ark commands!
```

---

### Launching Her First Instance

```bash
$ ark instance launch --type m5.xlarge --purpose "Sequence alignment"

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ’» EC2 Instance Launch                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â†’ Instance configuration:
  Type: m5.xlarge (4 vCPUs, 16GB RAM)
  Cost: $0.192/hour (~$140/month if running 24/7)
  
  âš ï¸  COST WARNING: This will cost $4.61 per day if left running!

â†’ Recommended: Set auto-shutdown
  Shut down after idle for: [1h/4h/8h/12h/24h/never]: 4h

  âœ“ Instance will auto-shutdown after 4 hours of inactivity
  ğŸ’¡ This could save you ~$100/month!

â†’ Selecting AMI (operating system)...
  âœ“ Using: UCLA Bio-Linux 2024 (pre-configured for genomics)
  
  Includes: BWA, BLAST, samtools, Python 3.11, R 4.3

â†’ Configuring security group...
  âœ“ SSH access from your IP only
  âœ“ No public internet access (uses UCLA VPN)

â†’ Creating SSH key pair...
  âœ“ Key saved: ~/.ssh/sarah-genomics-key.pem
  
  âš ï¸  Keep this file safe! It's your password.

â†’ Launching instance...
  â ‹ Requesting capacity...
  â ™ Instance starting...
  â ¹ Waiting for instance to be ready...
  
  âœ“ Instance running: i-0123456789abcdef

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âœ… Instance Ready!                                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Instance ID: i-0123456789abcdef                             â•‘
â•‘  Public IP: 34.216.45.123                                    â•‘
â•‘  Status: Running                                             â•‘
â•‘  Auto-shutdown: After 4h idle                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Connect via SSH:

  ssh -i ~/.ssh/sarah-genomics-key.pem ec2-user@34.216.45.123

Or use Ark's built-in SSH:

  ark instance connect --id i-0123456789abcdef

ğŸ’¡ Your S3 bucket is already mounted at /mnt/sarah-genomics-data/

â±ï¸  Total time: 3m 12s
```

---

### Week 2 - Sarah is Self-Sufficient

**What happened between Day 1 and Week 2:**

Over the past two weeks, Sarah has:
- âœ“ Completed **Module 2 (IAM & Identity Management)** when she needed to give her grad student read-only access
- âœ“ Uploaded 487 GB of genomic sequencing data to S3
- âœ“ Launched and terminated 5 compute instances for different analyses
- âœ“ Set up multiple billing alerts and stayed within her $150/month budget
- âœ“ Shared data securely with two external collaborators
- âœ“ Run weekly security audits (recommended practice)

**She's now using Ark routinely as part of her research workflow:**

```bash
$ ark audit scan

Running security audit on all your resources...

âœ… Overall Security Score: 94/100

Findings:

âœ“ S3 Buckets (2)
  â€¢ sarah-genomics-data: Perfect âœ“
  â€¢ sarah-results: Perfect âœ“

âœ“ EC2 Instances (1)
  â€¢ i-0123456789abcdef: Auto-shutdown enabled âœ“
  
âš ï¸  IAM
  â€¢ MFA not enabled on your user account
    Fix: ark iam mfa enable
    
ğŸ’° Cost Optimization
  â€¢ You could save $45/month by switching idle instances to t3.medium
    Current spend: $127/month (on track)
    Billing alarm: $100/month (triggered - check email!)

âœ“ Compliance
  â€¢ All resources properly tagged âœ“
  â€¢ Access logging enabled âœ“
  â€¢ Encryption at rest enabled âœ“

ğŸ“Š Full report: ~/ark-audit-report-2025-12-15.pdf
```

---

### Summary: Sarah's Journey

**Total Time Investment:**
- Installation & setup: 15 minutes
- Training: 120 minutes (2 hours, spaced over 2 days)
- First bucket creation: 5 minutes
- First instance launch: 10 minutes

**Total: ~2.5 hours** from zero to productive AWS researcher

**Training Breakdown:**
- Module 1: AWS Basics (35 min)
- Module 2: IAM & Identity Management (25 min) - completed Day 2
- Module 3: UC Data Classification (25 min)
- Module 4: S3 Storage Security (35 min)

**What Sarah Can Now Do:**
âœ“ Store and share research data securely  
âœ“ Launch compute instances for analysis  
âœ“ Monitor and control costs  
âœ“ Understand compliance requirements  
âœ“ Self-audit security posture  
âœ“ Know when to ask for help

**Security Incidents Prevented:**
- âœ— Unencrypted sensitive data
- âœ— Publicly accessible buckets  
- âœ— Runaway compute costs
- âœ— Missing audit trails
- âœ— Non-compliant data handling

**IT Support Tickets Avoided:**
- "How do I use AWS?" â†’ Trained via tool
- "I forgot to shut down my instance!" â†’ Auto-shutdown
- "My bill is $5000!" â†’ Billing alarms + cost education
- "Is my data secure?" â†’ Built-in compliance

---

## Appendix B: Module Template Structure

This appendix shows how training modules are structured and customized. Institutional administrators can modify these templates to meet specific requirements.

---

### Module Configuration File: `module.yaml`

```yaml
# Module metadata and configuration
module:
  id: "03-data-classification"
  version: "2.1.0"
  name: "UC Data Classification (P1-P4)"
  short_description: "Understanding data sensitivity and protection requirements"
  estimated_minutes: 25
  
  # What this module teaches
  learning_objectives:
    - "Classify data using UC P1-P4 framework"
    - "Identify PII and regulated data types"
    - "Understand legal frameworks (FERPA, HIPAA, CUI)"
    - "Recognize re-identification risks"
    - "Apply appropriate security controls per classification"
  
  # Required before this module
  prerequisites:
    - "01-aws-basics"
  
  # What becomes available after completion
  unlocks:
    commands:
      - "ark bucket create"
      - "ark classify"
    next_modules:
      - "04-s3-security"
  
  # Passing requirements
  completion_criteria:
    quiz_passing_score: 85  # Higher for compliance content
    hands_on_required: true
    scenario_passing_score: 90

# Content sources (can be remote URLs or local files)
content:
  tutorial: "https://ucla-training.s3.amazonaws.com/modules/03/tutorial.md"
  quiz: "https://ucla-training.s3.amazonaws.com/modules/03/quiz.yaml"
  scenarios: "https://ucla-training.s3.amazonaws.com/modules/03/scenarios.yaml"
  resources:
    - name: "UC Data Classification Policy"
      url: "https://policy.ucop.edu/doc/7000543/BFB-IS-3"
    - name: "FERPA Quick Reference"
      url: "https://it.ucla.edu/security/ferpa"
    - name: "HIPAA Compliance Guide"
      url: "https://hipaa.ucla.edu/guide"

# Institution-specific customization
customization:
  institution: "UCLA"
  ciso_sponsor: true  # Indicates CISO office reviewed this module
  
  # Institution-specific sections to inject
  custom_sections:
    - position: "after_intro"
      content_url: "https://ucla-training.s3.amazonaws.com/modules/03/ucla-specific.md"
      title: "UCLA-Specific Requirements"
    
    - position: "before_quiz"
      content_url: "https://ucla-training.s3.amazonaws.com/modules/03/case-studies.md"
      title: "Real UCLA Incidents (Anonymized)"
  
  # Override default contact information
  contacts:
    questions: "your institutional data classification office"
    incidents: "your institutional security incident response team"
    compliance: "your institutional HIPAA compliance office"

# Analytics and tracking
tracking:
  record_time_spent: true
  record_quiz_attempts: true
  record_common_mistakes: true
  send_completion_to: "https://ucla-training.ucla.edu/api/completion"

# Compliance attestation
compliance:
  reviewed_by: "UCLA CISO Office"
  review_date: "2025-11-15"
  next_review: "2026-05-15"
  frameworks_covered:
    - "UC BFB-IS-3 (Data Classification)"
    - "FERPA"
    - "HIPAA"
    - "NIST 800-171 (CUI)"
```

---

### Tutorial Content: `tutorial.md`

Tutorial content is written in enhanced Markdown with special syntax for interactive elements:

```markdown
# Module 3: UC Data Classification

## Section 1: Introduction

:::info
This module is sponsored by the UCLA CISO Office to ensure 
all researchers understand data protection requirements.
:::

Understanding data sensitivity is CRITICAL for compliance and security.

:::warning title="Getting This Wrong Has Consequences"
- Federal fines ($100k - $50M+ per incident)
- Loss of grant funding
- IRB suspension
- Legal liability
- Reputational damage to UCLA
:::

---

## Section 2: The Four Protection Levels

:::classification level="P1"
### P1 - Public Information

**Definition**: Information intended for public distribution

**Examples**:
- Published research papers
- Public course catalogs
- Campus maps

**Requirements**: None (already public)

**AWS Configuration**: Standard S3, no special controls
:::

:::classification level="P3" highlight="true"
### P3 - Protected Information â­ MOST COMMON

**Definition**: Sensitive data requiring protection

**Examples**:
- Personal Identifiable Information (PII)
  - Names, addresses, phone numbers
  - Email addresses, student IDs
- Student records (FERPA protected)
- De-identified health data
- Research data under confidentiality agreements

**Legal Frameworks**:
- FERPA (Family Educational Rights and Privacy Act)
- PII protection laws (CCPA, GDPR if applicable)
- Contractual confidentiality obligations

**Requirements**:
âœ“ Encryption at rest (REQUIRED)
âœ“ Encryption in transit (REQUIRED)
âœ“ Access logging for audits
âœ“ Strong access controls
âœ“ MFA for administrators

**AWS Configuration**: Ark P3 configuration enforces ALL requirements

:::alert type="danger"
**Common Mistake**: "It's de-identified so it's fine"

Even de-identified data can often be re-identified! When in doubt, treat as P3.
:::
:::

---

## Section 3: Real World Examples

:::case-study severity="high"
### Case Study: The "Anonymous" Survey Breach

**Institution**: Major Research University (2024)

**Scenario**: Researcher collected "anonymous" health surveys

**What they included**:
- Zip code
- Age (exact)
- Gender
- Medical condition

**The Problem**: These 4 data points can identify ~87% of the US population

**Classification Error**: Treated as P2, actually P3 (possibly P4!)

**Consequence**: 
- Data breach notification to 1,200 participants
- $250,000 fine
- IRB investigation
- 6-month research suspension

**Lesson**: Combinations of "non-sensitive" data = sensitive data
:::

---

## Section 4: Interactive Exercise

:::interactive type="classification-exercise"
**Exercise**: Classify this dataset

You have a dataset containing:
- Genomic sequences from fruit flies (Drosophila)
- No human subjects
- No personally identifiable information
- Funded by NSF grant
- Will be published when analysis complete
- No confidentiality agreements

What classification level?

[P1] [P2] [P3] [P4]

:::feedback correct="P2"
âœ… **Correct!** This is P2 (Internal) because:

- Not yet published (so not P1)
- No PII or regulated data (so not P3/P4)
- Internal research data until publication
- Non-human subject research

**When you publish, you can reclassify to P1.**

:::tip
Use this command to reclassify later:
```bash
ark bucket reclassify --name my-bucket --from P2 --to P1
```
:::
:::

---

## Section 5: Decision Tree

:::decision-tree
# Data Classification Decision Tree

**Start**: Does your data contain ANY of the following?

- Names, email addresses, phone numbers?
  â†’ YES: **At least P3**
  
- Student records or grades?
  â†’ YES: **P3 (FERPA applies)**
  
- Health information (even de-identified)?
  â†’ YES: **At least P3, possibly P4 if identifiable**
  
- Financial data, SSNs, credit cards?
  â†’ YES: **P4 (stop, contact CISO office)**
  
- Under confidentiality agreement?
  â†’ YES: **Read agreement, probably P3**
  
- Export controlled (ITAR/EAR)?
  â†’ YES: **P4 (stop, contact export control office)**
  
- Will be published/public eventually?
  â†’ YES but not yet: **P2 until published**
  
- None of the above?
  â†’ **Probably P1 or P2, but verify with PI**

:::help
**Still unsure?** That's OK!

Contact: your institutional data classification office

Better to ask than to misclassify.
:::
:::

---

## Section 6: UCLA-Specific Requirements

<!-- This section is injected from custom_sections in module.yaml -->

{{% custom_section position="after_intro" %}}

---

## Checkpoint Quiz

You must score 85% or higher to proceed.

{{% quiz source="quiz.yaml" %}}
```

---

### Quiz Definition: `quiz.yaml`

```yaml
# Quiz configuration
quiz:
  id: "03-data-classification-quiz"
  passing_score: 85
  randomize_questions: true
  randomize_answers: true
  max_attempts: 3
  show_correct_answers_after: 2  # After 2 attempts, show correct answers

questions:
  - id: "q1-identify-p3"
    type: "multiple_choice"
    points: 20
    question: |
      You have a dataset with: age (binned in 5-year ranges), 
      zip code, and diagnosis. No names. What classification level?
    
    options:
      - id: "a"
        text: "P1 - It's de-identified"
        correct: false
      
      - id: "b"
        text: "P2 - Internal use only"
        correct: false
      
      - id: "c"
        text: "P3 - Can be re-identified"
        correct: true
      
      - id: "d"
        text: "P4 - Contains health info"
        correct: false
    
    feedback:
      correct: |
        âœ… CORRECT! Even without names, this is P3 because:
        
        - Age + zip code + diagnosis = potentially identifiable
        - Health information requires protection even when de-identified
        - Could violate HIPAA if re-identified
        
        This is called "quasi-identifiers" - seemingly anonymous
        data that can be combined to identify individuals.
      
      incorrect: |
        âŒ Not quite. Consider:
        
        - Can these data points identify someone?
        - What if combined with public databases?
        - Does it contain health information?
        
        Think about re-identification risk.
    
    resources:
      - "https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-identification/"

  - id: "q2-data-sharing"
    type: "multiple_choice"
    points: 20
    question: |
      Your collaborator at Stanford needs access to your P3 research data.
      What do you need?
    
    options:
      - id: "a"
        text: "Just share an S3 link"
        correct: false
      
      - id: "b"
        text: "Data sharing agreement + BAA if needed"
        correct: true
      
      - id: "c"
        text: "Their email address"
        correct: false
      
      - id: "d"
        text: "Nothing special - they're at a university"
        correct: false
    
    feedback:
      correct: |
        âœ… PERFECT! For P3 data sharing, you need:
        
        1. Data Sharing Agreement (legal framework)
        2. Business Associate Agreement if health data (HIPAA)
        3. Document what data is shared and why
        4. Time-limited access (not permanent)
        5. UCLA IRB approval if human subjects
        
        Contact: your institutional data sharing office for templates

  - id: "q3-classification-error"
    type: "multiple_choice"
    points: 20
    question: |
      ğŸš¨ COMPLIANCE SCENARIO: You discover you've been storing
      what you thought was P2 data, but it actually contains 
      email addresses (P3). What do you do?
    
    options:
      - id: "a"
        text: "Delete the emails and move on"
        correct: false
      
      - id: "b"
        text: "Immediately report to CISO, re-classify, audit access"
        correct: true
      
      - id: "c"
        text: "Just fix it going forward"
        correct: false
      
      - id: "d"
        text: "Hope no one noticed"
        correct: false
    
    feedback:
      correct: |
        âœ… CRITICAL! When you discover a classification error:
        
        IMMEDIATE actions:
        1. Stop any current data sharing
        2. Email: your institutional security incident response team
        3. Document: What data? How long? Who had access?
        
        The CISO office will help you:
        - Re-classify correctly
        - Audit who accessed the data
        - Implement proper controls
        - Determine if breach notification needed
        
        ğŸ¯ Key principle: It's never wrong to report.
    
    tags: ["incident-response", "compliance", "critical"]

  - id: "q4-bucket-mixing"
    type: "multiple_choice"
    points: 20
    question: |
      Can you mix P2 and P3 data in the same S3 bucket?
    
    options:
      - id: "a"
        text: "Yes, it's fine"
        correct: false
      
      - id: "b"
        text: "Yes, but in separate folders"
        correct: false
      
      - id: "c"
        text: "No, always use separate buckets"
        correct: true
      
      - id: "d"
        text: "Only with special permission"
        correct: false
    
    feedback:
      correct: |
        âœ… CORRECT! Best practice: Separate buckets per classification.
        
        Why?
        - Bucket-level encryption settings differ
        - Access controls are simpler
        - Audit logging is clearer
        - Reduces accidental exposure risk
        - Compliance audits are easier

  - id: "q5-scenario"
    type: "scenario"
    points: 20
    question: |
      **Scenario**: You're analyzing survey data that includes:
      - Participant ID (non-identifiable code)
      - County of residence
      - Year of birth
      - Political affiliation
      - Voting history
      
      This data will inform policy recommendations. How do you classify it?
    
    correct_classification: "P3"
    
    reasoning_required: true
    min_reasoning_length: 50
    
    sample_reasoning: |
      This should be classified as P3 because:
      
      1. Demographic data (county, year of birth) combined with
         sensitive information (political affiliation, voting history)
         could potentially identify individuals
      
      2. Political information is sensitive even when aggregated
      
      3. While participant IDs are non-identifiable, the combination
         of other factors creates re-identification risk
      
      4. Policy recommendations may involve sensitive populations
    
    grading_rubric:
      - keyword: "re-identification"
        points: 5
      - keyword: "sensitive"
        points: 3
      - keyword: "combination"
        points: 3
      - mentions_demographics: true
        points: 4
      - mentions_political_sensitivity: true
        points: 5

# Post-quiz feedback
post_quiz:
  pass:
    message: |
      ğŸ‰ Excellent work! You've demonstrated strong understanding
      of UCLA's data classification framework.
      
      Score: {score}%
      
      You can now create S3 buckets with proper classification.
    
    next_steps:
      - "Continue to Module 4: S3 Storage Security"
      - "Download classification quick reference"
      - "Bookmark: your institutional data classification office"
  
  fail:
    message: |
      You scored {score}% (need 85% to pass).
      
      Don't worry! Data classification is complex.
      
      Review these sections:
      {weak_areas}
      
      You have {attempts_remaining} attempt(s) remaining.
    
    resources:
      - "Review the decision tree in Section 5"
      - "Read the case studies in Section 3"
      - "Contact your institutional data classification office for help"
```

---

### Scenarios: `scenarios.yaml`

```yaml
# Interactive scenario-based learning
scenarios:
  - id: "scenario-classify-research-data"
    title: "Classify Your Research Data"
    description: |
      Walk through a realistic data classification scenario
    
    steps:
      - prompt: "What type of research data do you work with?"
        options:
          - "Human subjects research"
          - "Animal research"
          - "Computational/modeling"
          - "Materials science"
          - "Other"
        branch_on_selection: true
      
      - prompt: "Does your data contain any identifiable information about individuals?"
        type: "yes_no"
        if_yes:
          guidance: "This likely requires P3 or P4 classification"
          next: "identify-pii-types"
        if_no:
          next: "check-other-sensitive"
      
      # ... more scenario steps ...
    
    completion:
      requires_correct_classification: true
      provides_certificate: true
```

---

### Customization Points for Institutions

Institutions can customize:

1. **Content URLs**: Host training materials on their own infrastructure
2. **Custom sections**: Inject institution-specific content anywhere
3. **Contact information**: Override default support contacts
4. **Passing scores**: Adjust based on risk tolerance
5. **Case studies**: Add institution-specific incidents (anonymized)
6. **Legal frameworks**: Emphasize relevant compliance requirements
7. **Quiz questions**: Add institution-specific scenarios
8. **Resources**: Link to internal policies and procedures
9. **CISO sponsorship**: Mark modules as officially reviewed
10. **Compliance tracking**: Send completion data to institutional systems

---

### Example: Adapting for Different Institutions

**UCLA Version** (Current):
- UC P1-P4 classification
- FERPA, HIPAA, CUI emphasis
- UCLA CISO contacts
- UCLA-specific case studies

**MIT Version** (Hypothetical):
```yaml
customization:
  institution: "MIT"
  classification_system: "TLP"  # Traffic Light Protocol
  frameworks:
    - "ITAR/EAR" # Export control emphasis
    - "CMMC Level 2"
    - "DFARS"
  contacts:
    questions: "institutional information security"
    incidents: "institutional CERT team"
```

**NIH Intramural** (Hypothetical):
```yaml
customization:
  institution: "NIH"
  classification_system: "NIH-specific"
  frameworks:
    - "FISMA High"
    - "FedRAMP"
    - "HIPAA (strict)"
  additional_requirements:
    - "All data is P3 minimum"
    - "Requires ISSO approval"
```

---

### Benefits of This Template System

**For Ark Tool:**
- Consistent learning experience
- Programmatic content validation
- Automated progress tracking
- Easy A/B testing of content

**For Institutions:**
- Full content control
- Rapid deployment of updates
- Compliance audit trail
- Multi-tenancy support

**For Learners:**
- Always current content
- Institution-relevant examples
- Consistent UI/UX
- Offline capability (cached content)

---
